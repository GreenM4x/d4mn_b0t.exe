{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = %env API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUTUBE_API_SERVICE_NAME = 'youtube'\n",
    "YOUTUBE_API_VERSION = 'v3'\n",
    "\n",
    "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_channel_title(channel_title):\n",
    "    # Remove 'VEVO' from the channel title\n",
    "    channel_title = re.sub(r'vevo', '', channel_title, flags=re.IGNORECASE)\n",
    "    # Remove '- Topic' from the channel title\n",
    "    channel_title = re.sub(r'- Topic', '', channel_title, flags=re.IGNORECASE)\n",
    "    # Insert spaces before capital letters (if words are concatenated)\n",
    "    channel_title = re.sub(r'(?<=[a-z])(?=[A-Z])', ' ', channel_title)\n",
    "    # Remove extra spaces\n",
    "    channel_title = channel_title.strip()\n",
    "    return channel_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(title):\n",
    "    # List of patterns to remove\n",
    "    patterns = [\n",
    "        r'\\(.*?official music video.*?\\)',\n",
    "        r'\\[.*?official music video.*?\\]',\n",
    "        r'\\(.*?official video.*?\\)',\n",
    "        r'\\[.*?official video.*?\\]',\n",
    "        r'\\(.*?official mv.*?\\)',\n",
    "        r'\\[.*?official mv.*?\\]', \n",
    "        r'\\(.*?lyrics.*?\\)',\n",
    "        r'\\[.*?lyrics.*?\\]',\n",
    "        r'\\(.*?audio.*?\\)',\n",
    "        r'\\[.*?audio.*?\\)',\n",
    "        r'\\(.*?lyric video.*?\\)',\n",
    "        r'\\[.*?lyric video.*?\\)',\n",
    "        r'\\(.*?official visualizer.*?\\)',\n",
    "        r'\\[.*?official visualizer.*?\\]',\n",
    "        r'\\(.*?lyric.*?\\)',\n",
    "        r'\\[.*?lyric.*?\\]',\n",
    "        r'-\\s*visualizer',\n",
    "        r'-\\s*visualiser',\n",
    "        r'\\(.*?mv.*?\\)',\n",
    "        r'\\[.*?mv.*?\\]',\n",
    "        r'\\(.*?hd.*?\\)',\n",
    "        r'\\[.*?hd.*?\\]',\n",
    "        r'\\(.*?hq.*?\\)',\n",
    "        r'\\[.*?hq.*?\\]',\n",
    "        r'official mv',\n",
    "        r'lyrics in video \\+ description',    # Added pattern\n",
    "        r'lyric video',                        # Added pattern\n",
    "        r'lyrics hd/hq',                       # Added pattern\n",
    "        r'lyrics hq/hd',                       # Added pattern (reverse order)\n",
    "        r'lyrics',                             # Added pattern\n",
    "        r'lyric',                              # Added pattern\n",
    "        r'ft\\.',                               # We'll handle 'ft.' and 'feat.' in another function\n",
    "        r'feat\\.',\n",
    "        r'vevo',\n",
    "        r'\\\"',\n",
    "        r'\\'',\n",
    "        r'\\|.*',\n",
    "    ]\n",
    "\n",
    "    # Remove unwanted patterns\n",
    "    for pattern in patterns:\n",
    "        title = re.sub(pattern, '', title, flags=re.IGNORECASE)\n",
    "    # Remove extra spaces and special characters at the ends\n",
    "    title = title.strip(' -–—_|')\n",
    "    title = re.sub(r'\\s+', ' ', title)\n",
    "    return title.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_artists(artist_str):\n",
    "    # Define separators\n",
    "    separators = [',', '&', ' and ']\n",
    "    # Create a regex pattern to split on any of the separators\n",
    "    regex_pattern = '|'.join(map(re.escape, separators))\n",
    "    # Split the artist string\n",
    "    artists_list = [a.strip() for a in re.split(regex_pattern, artist_str) if a.strip()]\n",
    "    return artists_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_featured_artists(text):\n",
    "    ft_pattern = r'(?i)\\b(ft\\.?|feat\\.?|featuring)\\b\\s*(.*)'\n",
    "    match = re.search(ft_pattern, text)\n",
    "    if match:\n",
    "        main_text = text[:match.start()].strip()\n",
    "        featured_artists_str = match.group(2).strip()\n",
    "        featured_artists = split_artists(featured_artists_str)\n",
    "        return main_text, featured_artists\n",
    "    else:\n",
    "        return text.strip(), []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_videos(youtube, playlist_id):\n",
    "    videos = []\n",
    "    next_page_token = None\n",
    "    seen_page_tokens = set()\n",
    "\n",
    "    while True:\n",
    "        # Build the request parameters\n",
    "        request_params = {\n",
    "            'part': 'contentDetails',\n",
    "            'playlistId': playlist_id,\n",
    "            'maxResults': 50,\n",
    "        }\n",
    "        if next_page_token:\n",
    "            request_params['pageToken'] = next_page_token\n",
    "\n",
    "        try:\n",
    "            pl_request = youtube.playlistItems().list(**request_params)\n",
    "            pl_response = pl_request.execute()\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "        # Extract video IDs\n",
    "        video_ids = [item['contentDetails']['videoId'] for item in pl_response.get('items', [])]\n",
    "        videos.extend(video_ids)\n",
    "\n",
    "        # Get the next page token\n",
    "        previous_page_token = next_page_token\n",
    "        next_page_token = pl_response.get('nextPageToken')\n",
    "\n",
    "        # Debugging: Print the page tokens\n",
    "        # page_number = len(videos) // 50 + 1\n",
    "        # print(f'Page {page_number}: Retrieved {len(video_ids)} videos.')\n",
    "        # print(f'Previous page token: {previous_page_token}')\n",
    "        # print(f'Next page token: {next_page_token}')\n",
    "\n",
    "        # Check if we've seen this page token before\n",
    "        if next_page_token in seen_page_tokens:\n",
    "            # print(\"Next page token has been seen before. Exiting loop to prevent infinite execution.\")\n",
    "            break\n",
    "\n",
    "        # If next_page_token is None, we've reached the last page\n",
    "        if not next_page_token:\n",
    "            # print(\"No more pages. Exiting loop.\")\n",
    "            break\n",
    "\n",
    "        # Add the current next_page_token to the set of seen tokens\n",
    "        seen_page_tokens.add(next_page_token)\n",
    "\n",
    "    return videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(youtube, video_ids):\n",
    "    video_details = []\n",
    "    special_char_patterns = r'[\\(\\[\\{]([^)\\]\\}]+)[\\)\\]\\}]'\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part='snippet',\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            video_id = item['id']\n",
    "            snippet = item['snippet']\n",
    "            full_title = snippet['title']\n",
    "            channel_title = snippet['channelTitle']\n",
    "\n",
    "            # Clean the title\n",
    "            cleaned_title = clean_title(full_title)\n",
    "\n",
    "            # Remove any text in parentheses or brackets\n",
    "            cleaned_title = re.sub(r'\\(.*?\\)', '', cleaned_title)\n",
    "            cleaned_title = re.sub(r'\\[.*?\\]', '', cleaned_title)\n",
    "            cleaned_title = re.sub(r'\\{.*?\\}', '', cleaned_title)\n",
    "            cleaned_title = cleaned_title.strip()\n",
    "\n",
    "            # Split the title to extract artist and song title\n",
    "            separators = [' - ', '-', ':', '|', '–', '—']\n",
    "            regex_pattern = '|'.join(map(re.escape, separators))\n",
    "            split_title = re.split(regex_pattern, cleaned_title, maxsplit=1)\n",
    "\n",
    "            if len(split_title) == 2:\n",
    "                artist, song_title = split_title\n",
    "            elif ' by ' in cleaned_title.lower():\n",
    "                song_title, artist = cleaned_title.rsplit(' by ', 1)\n",
    "            else:\n",
    "                artist = ''\n",
    "                song_title = cleaned_title\n",
    "\n",
    "            artist = artist.strip()\n",
    "            song_title = song_title.strip()\n",
    "\n",
    "            # If artist is empty, use the cleaned channel title\n",
    "            if not artist:\n",
    "                artist = clean_channel_title(channel_title)\n",
    "\n",
    "            # Initialize singers_list\n",
    "            singers_list = []\n",
    "\n",
    "            # Extract featured artists from artist\n",
    "            artist, featured_artists_from_artist = extract_featured_artists(artist)\n",
    "            # Extract featured artists from song_title\n",
    "            song_title, featured_artists_from_title = extract_featured_artists(song_title)\n",
    "\n",
    "            # Combine all artists\n",
    "            main_artists = split_artists(artist)\n",
    "            singers_list.extend(main_artists)\n",
    "            singers_list.extend(featured_artists_from_artist)\n",
    "            singers_list.extend(featured_artists_from_title)\n",
    "\n",
    "            # Remove duplicates and normalize singers_list\n",
    "            singers_list = list(set(singer.strip() for singer in singers_list if singer.strip()))\n",
    "\n",
    "            video_details.append({\n",
    "                \"url\": f\"https://www.youtube.com/watch?v={video_id}\",\n",
    "                \"title\": song_title,\n",
    "                \"singers\": singers_list\n",
    "            })\n",
    "\n",
    "    return video_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos retrieved from playlist RDCLAK5uy_lBGRuQnsG37Akr1CY4SxL0VWFbPrbO4gs: 199\n",
      "Number of videos retrieved from playlist RDCLAK5uy_kmPRjHDECIcuVwnKsx2Ng7fyNgFKWNJFs: 94\n",
      "Number of videos retrieved from playlist RDCLAK5uy_lBNUteBRencHzKelu5iDHwLF6mYqjL-JU: 89\n",
      "Number of videos retrieved from playlist RDCLAK5uy_nZiG9ehz_MQoWQxY5yElsLHCcG0tv9PRg: 199\n",
      "Number of videos retrieved from playlist RDCLAK5uy_nmS3YoxSwVVQk9lEQJ0UX4ZCjXsW_psU8: 299\n",
      "Number of videos retrieved from playlist PLB5Ac5TbLc2OHUC5uaAuFdbxMXQK3ZaAF: 114\n",
      "An error occurred: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/playlistItems?part=contentDetails&playlistId=RDCLAK5uy_mGYde2Wyx9INZd6GbPcMWkxDOu6UtmedwPLOhV0FrFphUfHqxfhIBju7zu_2CTqG01FRDCLAK5uy_mplKe9BIYCO3ZuNWSHZr48bm9DUDzbWnE&maxResults=50&key=AIzaSyCoop3L4OhBNltsNFYaZb2CNBTXstnqjTA&alt=json returned \"The playlist identified with the request's <code>playlistId</code> parameter cannot be found.\". Details: \"[{'message': \"The playlist identified with the request's <code>playlistId</code> parameter cannot be found.\", 'domain': 'youtube.playlistItem', 'reason': 'playlistNotFound', 'location': 'playlistId', 'locationType': 'parameter'}]\">\n",
      "Number of videos retrieved from playlist RDCLAK5uy_mGYde2Wyx9INZd6GbPcMWkxDOu6UtmedwPLOhV0FrFphUfHqxfhIBju7zu_2CTqG01FRDCLAK5uy_mplKe9BIYCO3ZuNWSHZr48bm9DUDzbWnE: 0\n",
      "Total number of videos before removing duplicates: 993\n",
      "Number of unique videos after removing duplicates by URL: 344\n",
      "Number of unique songs after removing duplicates by title and singers: 334\n"
     ]
    }
   ],
   "source": [
    "# Get all video IDs from the playlist\n",
    "playlist_ids = [\n",
    "    'RDCLAK5uy_lBGRuQnsG37Akr1CY4SxL0VWFbPrbO4gs', # On Everything: Today's Hip-Hop Hits\n",
    "    'RDCLAK5uy_kmPRjHDECIcuVwnKsx2Ng7fyNgFKWNJFs', # The Hit List\n",
    "    'RDCLAK5uy_lBNUteBRencHzKelu5iDHwLF6mYqjL-JU', # Pop Certified\n",
    "    'RDCLAK5uy_nZiG9ehz_MQoWQxY5yElsLHCcG0tv9PRg', # Classic Rock's Greatest Hits\n",
    "    'RDCLAK5uy_nmS3YoxSwVVQk9lEQJ0UX4ZCjXsW_psU8', # Pop's Biggest Hits\n",
    "    # 'RDCLAK5uy_nKsmIDujCJTYRInvAJirUkn0KjgwKNiZE', # Disney Songs\n",
    "    # 'RDCLAK5uy_lMzXQA761IIDTLJJwgpD67INZ8lL6UsVU', # Christian Music's Biggest Hits\n",
    "    'PLB5Ac5TbLc2OHUC5uaAuFdbxMXQK3ZaAF', # Most Iconic Songs of All Time\n",
    "    # 'RDCLAK5uy_k5vcGRXixxemtzK1eKDS7BeHys7mvYOdk' # Maximum Decibels: Today's Rock Hits\n",
    "    'RDCLAK5uy_mGYde2Wyx9INZd6GbPcMWkxDOu6Utmedw' # The Hits: '10s\n",
    "    'PLOhV0FrFphUfHqxfhIBju7zu_2CTqG01F' # Best Indie Rock Songs/ Alternative Playlist\n",
    "    'RDCLAK5uy_mplKe9BIYCO3ZuNWSHZr48bm9DUDzbWnE' # The Millennial Mixtape\n",
    "    # 'PL6Lt9p1lIRZ311J9ZHuzkR5A3xesae2pk' # Alternative rock of the 2000s\n",
    "]\n",
    "video_details = []\n",
    "\n",
    "# Get all video IDs from the playlists\n",
    "for playlist_id in playlist_ids:\n",
    "    video_ids = get_playlist_videos(youtube, playlist_id)\n",
    "    print(f'Number of videos retrieved from playlist {playlist_id}: {len(video_ids)}')\n",
    "    # Get video details and extend the list\n",
    "    video_details.extend(get_video_details(youtube, video_ids))\n",
    "\n",
    "print(f'Total number of videos before removing duplicates: {len(video_details)}')\n",
    "\n",
    "# Remove duplicates based on 'url' (video_id)\n",
    "unique_videos = {video['url']: video for video in video_details}\n",
    "video_details = list(unique_videos.values())\n",
    "print(f'Number of unique videos after removing duplicates by URL: {len(video_details)}')\n",
    "\n",
    "# Now remove duplicates based on song title and singers\n",
    "unique_songs = {}\n",
    "for video in video_details:\n",
    "    # Create a key using the song title and sorted list of singers\n",
    "    key = (\n",
    "        video['title'].strip().lower(),  # Normalize the song title\n",
    "        tuple(sorted(singer.strip().lower() for singer in video['singers']))  # Normalize and sort singers\n",
    "    )\n",
    "    if key not in unique_songs:\n",
    "        unique_songs[key] = video  # Add the video if the key is not present\n",
    "\n",
    "# Update video_details with the unique songs\n",
    "video_details = list(unique_songs.values())\n",
    "print(f'Number of unique songs after removing duplicates by title and singers: {len(video_details)}')\n",
    "\n",
    "# Save data to CSV and JSON\n",
    "data = pd.DataFrame(video_details)\n",
    "data.to_csv('playlist_videos_cleaned.csv', index=False)\n",
    "\n",
    "with open('playlist_videos.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(video_details, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
